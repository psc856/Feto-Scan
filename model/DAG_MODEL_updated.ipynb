{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJ4l6K0aS8p2",
    "outputId": "06b27fcc-2511-428d-b98c-867eb4a21774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "unrar is already the newest version (1:6.1.5-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install unrar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "br9aEv8tRDP6",
    "outputId": "caf2973c-5fea-4109-885b-9e07d8338d37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: dataset\n",
      "['Augmentedsrc', 'Augmentedmask']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Define the ZIP file path and extraction directory\n",
    "zip_path = \"DataSet.zip\"        # change if your file is in another location\n",
    "extract_to = \"dataset\"\n",
    "\n",
    "# Create the extraction directory if it doesn't exist\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "# List extracted files to verify\n",
    "print(f\"Files extracted to: {extract_to}\")\n",
    "print(os.listdir(extract_to))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "509bcbFMW6Tr",
    "outputId": "13dec6e7-4856-4193-ddfb-ee2f706b83c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images and masks: 29940\n",
      "Image CSV file created at: image_paths.csv\n",
      "Mask CSV file created at: mask_paths.csv\n",
      "Image paths preview:\n",
      "                       ImagePath\n",
      "0   dataset/Augmentedsrc/0_1.png\n",
      "1  dataset/Augmentedsrc/0_10.png\n",
      "2  dataset/Augmentedsrc/0_11.png\n",
      "3  dataset/Augmentedsrc/0_12.png\n",
      "4  dataset/Augmentedsrc/0_13.png\n",
      "Mask paths preview:\n",
      "                         MaskPath\n",
      "0   dataset/Augmentedmask/0_1.png\n",
      "1  dataset/Augmentedmask/0_10.png\n",
      "2  dataset/Augmentedmask/0_11.png\n",
      "3  dataset/Augmentedmask/0_12.png\n",
      "4  dataset/Augmentedmask/0_13.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the paths to the image and mask directories\n",
    "image_dir = \"dataset/Augmentedsrc\"\n",
    "mask_dir = \"dataset/Augmentedmask\"\n",
    "\n",
    "# List and sort all image and mask files for consistent mapping\n",
    "image_files = sorted(os.listdir(image_dir))  # Sorting ensures correct pair matching\n",
    "mask_files = sorted(os.listdir(mask_dir))   # Sorting ensures correct pair matching\n",
    "\n",
    "# Verify that the number of images matches the number of masks\n",
    "if len(image_files) != len(mask_files):\n",
    "    print(f\"Warning: Number of images ({len(image_files)}) and masks ({len(mask_files)}) do not match!\")\n",
    "else:\n",
    "    print(f\"Number of images and masks: {len(image_files)}\")\n",
    "\n",
    "# Ensure consistent file matching by filename (if applicable)\n",
    "for img, msk in zip(image_files, mask_files):\n",
    "    if os.path.splitext(img)[0] != os.path.splitext(msk)[0]:\n",
    "        print(f\"Mismatch detected: {img} does not match {msk}\")\n",
    "\n",
    "# Create file paths\n",
    "image_paths = [os.path.join(image_dir, img) for img in image_files]\n",
    "mask_paths = [os.path.join(mask_dir, msk) for msk in mask_files]\n",
    "\n",
    "# Create separate DataFrames for images and masks\n",
    "image_df = pd.DataFrame({\"ImagePath\": image_paths})\n",
    "mask_df = pd.DataFrame({\"MaskPath\": mask_paths})\n",
    "\n",
    "# Save the DataFrames to separate CSV files\n",
    "image_csv_path = \"image_paths.csv\"\n",
    "mask_csv_path = \"mask_paths.csv\"\n",
    "\n",
    "image_df.to_csv(image_csv_path, index=False, header=False)\n",
    "mask_df.to_csv(mask_csv_path, index=False, header=False)\n",
    "\n",
    "print(f\"Image CSV file created at: {image_csv_path}\")\n",
    "print(f\"Mask CSV file created at: {mask_csv_path}\")\n",
    "\n",
    "# Preview the first few rows of each CSV\n",
    "print(\"Image paths preview:\")\n",
    "print(image_df.head())\n",
    "\n",
    "print(\"Mask paths preview:\")\n",
    "print(mask_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PY9n3soegTb-",
    "outputId": "5305f656-9e88-448e-dbb5-4154116aad91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  True DAG-VNet Model Summary:\n",
      "Model: \"True_DAG_VNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 256, 256, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)          (None, 256, 256, 32)         320       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_64 (Ba  (None, 256, 256, 32)         128       ['conv2d_98[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_64 (ReLU)             (None, 256, 256, 32)         0         ['batch_normalization_64[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)          (None, 256, 256, 32)         9248      ['re_lu_64[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_65 (Ba  (None, 256, 256, 32)         128       ['conv2d_99[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)         (None, 256, 256, 32)         64        ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " add_28 (Add)                (None, 256, 256, 32)         0         ['batch_normalization_65[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_100[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_65 (ReLU)             (None, 256, 256, 32)         0         ['add_28[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)         (None, 256, 256, 32)         9248      ['re_lu_65[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_66 (Ba  (None, 256, 256, 32)         128       ['conv2d_101[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_66 (ReLU)             (None, 256, 256, 32)         0         ['batch_normalization_66[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)         (None, 256, 256, 32)         9248      ['re_lu_66[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_67 (Ba  (None, 256, 256, 32)         128       ['conv2d_102[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_29 (Add)                (None, 256, 256, 32)         0         ['batch_normalization_67[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_65[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_67 (ReLU)             (None, 256, 256, 32)         0         ['add_29[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 128, 128, 32)         0         ['re_lu_67[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)         (None, 128, 128, 64)         18496     ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_68 (Ba  (None, 128, 128, 64)         256       ['conv2d_103[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_68 (ReLU)             (None, 128, 128, 64)         0         ['batch_normalization_68[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)         (None, 128, 128, 64)         36928     ['re_lu_68[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_69 (Ba  (None, 128, 128, 64)         256       ['conv2d_104[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)         (None, 128, 128, 64)         2112      ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " add_30 (Add)                (None, 128, 128, 64)         0         ['batch_normalization_69[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_105[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_69 (ReLU)             (None, 128, 128, 64)         0         ['add_30[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)         (None, 128, 128, 64)         36928     ['re_lu_69[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_70 (Ba  (None, 128, 128, 64)         256       ['conv2d_106[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_70 (ReLU)             (None, 128, 128, 64)         0         ['batch_normalization_70[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)         (None, 128, 128, 64)         36928     ['re_lu_70[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_71 (Ba  (None, 128, 128, 64)         256       ['conv2d_107[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_31 (Add)                (None, 128, 128, 64)         0         ['batch_normalization_71[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_69[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_71 (ReLU)             (None, 128, 128, 64)         0         ['add_31[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 64, 64, 64)           0         ['re_lu_71[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)         (None, 64, 64, 128)          73856     ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_72 (Ba  (None, 64, 64, 128)          512       ['conv2d_108[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_72 (ReLU)             (None, 64, 64, 128)          0         ['batch_normalization_72[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)         (None, 64, 64, 128)          147584    ['re_lu_72[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_73 (Ba  (None, 64, 64, 128)          512       ['conv2d_109[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)         (None, 64, 64, 128)          8320      ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " add_32 (Add)                (None, 64, 64, 128)          0         ['batch_normalization_73[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_110[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_73 (ReLU)             (None, 64, 64, 128)          0         ['add_32[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)         (None, 64, 64, 128)          147584    ['re_lu_73[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_74 (Ba  (None, 64, 64, 128)          512       ['conv2d_111[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_74 (ReLU)             (None, 64, 64, 128)          0         ['batch_normalization_74[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)         (None, 64, 64, 128)          147584    ['re_lu_74[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_75 (Ba  (None, 64, 64, 128)          512       ['conv2d_112[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_33 (Add)                (None, 64, 64, 128)          0         ['batch_normalization_75[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_73[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_75 (ReLU)             (None, 64, 64, 128)          0         ['add_33[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, 32, 32, 128)          0         ['re_lu_75[0][0]']            \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)         (None, 32, 32, 256)          295168    ['max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (Ba  (None, 32, 32, 256)          1024      ['conv2d_113[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_76 (ReLU)             (None, 32, 32, 256)          0         ['batch_normalization_76[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)         (None, 32, 32, 256)          590080    ['re_lu_76[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_77 (Ba  (None, 32, 32, 256)          1024      ['conv2d_114[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)         (None, 32, 32, 256)          33024     ['max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " add_34 (Add)                (None, 32, 32, 256)          0         ['batch_normalization_77[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_115[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_77 (ReLU)             (None, 32, 32, 256)          0         ['add_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)         (None, 32, 32, 256)          590080    ['re_lu_77[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_78 (Ba  (None, 32, 32, 256)          1024      ['conv2d_116[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_78 (ReLU)             (None, 32, 32, 256)          0         ['batch_normalization_78[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)         (None, 32, 32, 256)          590080    ['re_lu_78[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_79 (Ba  (None, 32, 32, 256)          1024      ['conv2d_117[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_35 (Add)                (None, 32, 32, 256)          0         ['batch_normalization_79[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_77[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_79 (ReLU)             (None, 32, 32, 256)          0         ['add_35[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooli  (None, 16, 16, 256)          0         ['re_lu_79[0][0]']            \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)         (None, 16, 16, 512)          1180160   ['max_pooling2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_80 (Ba  (None, 16, 16, 512)          2048      ['conv2d_118[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_80 (ReLU)             (None, 16, 16, 512)          0         ['batch_normalization_80[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)         (None, 16, 16, 512)          2359808   ['re_lu_80[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_81 (Ba  (None, 16, 16, 512)          2048      ['conv2d_119[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)         (None, 16, 16, 512)          131584    ['max_pooling2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " add_36 (Add)                (None, 16, 16, 512)          0         ['batch_normalization_81[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_120[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_81 (ReLU)             (None, 16, 16, 512)          0         ['add_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)         (None, 16, 16, 512)          2359808   ['re_lu_81[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_82 (Ba  (None, 16, 16, 512)          2048      ['conv2d_121[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_82 (ReLU)             (None, 16, 16, 512)          0         ['batch_normalization_82[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)         (None, 16, 16, 512)          2359808   ['re_lu_82[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_83 (Ba  (None, 16, 16, 512)          2048      ['conv2d_122[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_37 (Add)                (None, 16, 16, 512)          0         ['batch_normalization_83[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_81[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_83 (ReLU)             (None, 16, 16, 512)          0         ['add_37[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2D  (None, 32, 32, 256)          524544    ['re_lu_83[0][0]']            \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_16 (TFO  (4,)                         0         ['conv2d_transpose_8[0][0]']  \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_17 (TFO  (4,)                         0         ['conv2d_transpose_8[0][0]']  \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_16[0][0]'\n",
      " 6 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_17[0][0]'\n",
      " 7 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.image.resize_16 (TFOpLa  (None, 32, 32, 256)          0         ['conv2d_transpose_8[0][0]',  \n",
      " mbda)                                                               'tf.__operators__.getitem_16[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_17[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.image.resize_17 (TFOpLa  (None, 32, 32, 256)          0         ['re_lu_79[0][0]',            \n",
      " mbda)                                                               'tf.__operators__.getitem_16[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_17[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)         (None, 32, 32, 128)          32896     ['tf.image.resize_16[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)         (None, 32, 32, 128)          32896     ['tf.image.resize_17[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 32, 32, 256)          0         ['conv2d_123[0][0]',          \n",
      " )                                                                   'conv2d_124[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)         (None, 32, 32, 256)          65792     ['concatenate_8[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)       (None, 32, 32, 256)          0         ['concatenate_8[0][0]',       \n",
      "                                                                     'conv2d_125[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)         (None, 32, 32, 256)          590080    ['multiply_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_84 (Ba  (None, 32, 32, 256)          1024      ['conv2d_126[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_84 (ReLU)             (None, 32, 32, 256)          0         ['batch_normalization_84[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)         (None, 32, 32, 256)          590080    ['re_lu_84[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_85 (Ba  (None, 32, 32, 256)          1024      ['conv2d_127[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_85 (ReLU)             (None, 32, 32, 256)          0         ['batch_normalization_85[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)         (None, 32, 32, 256)          590080    ['re_lu_85[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_86 (Ba  (None, 32, 32, 256)          1024      ['conv2d_128[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_38 (Add)                (None, 32, 32, 256)          0         ['batch_normalization_86[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_84[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_86 (ReLU)             (None, 32, 32, 256)          0         ['add_38[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2D  (None, 64, 64, 128)          131200    ['re_lu_86[0][0]']            \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_18 (TFO  (4,)                         0         ['conv2d_transpose_9[0][0]']  \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_19 (TFO  (4,)                         0         ['conv2d_transpose_9[0][0]']  \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_18[0][0]'\n",
      " 8 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_19[0][0]'\n",
      " 9 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.image.resize_18 (TFOpLa  (None, 64, 64, 128)          0         ['conv2d_transpose_9[0][0]',  \n",
      " mbda)                                                               'tf.__operators__.getitem_18[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_19[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.image.resize_19 (TFOpLa  (None, 64, 64, 128)          0         ['re_lu_75[0][0]',            \n",
      " mbda)                                                               'tf.__operators__.getitem_18[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_19[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)         (None, 64, 64, 64)           8256      ['tf.image.resize_18[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)         (None, 64, 64, 64)           8256      ['tf.image.resize_19[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate  (None, 64, 64, 128)          0         ['conv2d_129[0][0]',          \n",
      " )                                                                   'conv2d_130[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)         (None, 64, 64, 128)          16512     ['concatenate_9[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)       (None, 64, 64, 128)          0         ['concatenate_9[0][0]',       \n",
      "                                                                     'conv2d_131[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)         (None, 64, 64, 128)          147584    ['multiply_9[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_87 (Ba  (None, 64, 64, 128)          512       ['conv2d_132[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_87 (ReLU)             (None, 64, 64, 128)          0         ['batch_normalization_87[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)         (None, 64, 64, 128)          147584    ['re_lu_87[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_88 (Ba  (None, 64, 64, 128)          512       ['conv2d_133[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_88 (ReLU)             (None, 64, 64, 128)          0         ['batch_normalization_88[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)         (None, 64, 64, 128)          147584    ['re_lu_88[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_89 (Ba  (None, 64, 64, 128)          512       ['conv2d_134[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_39 (Add)                (None, 64, 64, 128)          0         ['batch_normalization_89[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_87[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_89 (ReLU)             (None, 64, 64, 128)          0         ['add_39[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2  (None, 128, 128, 64)         32832     ['re_lu_89[0][0]']            \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_20 (TFO  (4,)                         0         ['conv2d_transpose_10[0][0]'] \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_21 (TFO  (4,)                         0         ['conv2d_transpose_10[0][0]'] \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape_20[0][0]'\n",
      " 0 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape_21[0][0]'\n",
      " 1 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.image.resize_20 (TFOpLa  (None, 128, 128, 64)         0         ['conv2d_transpose_10[0][0]', \n",
      " mbda)                                                               'tf.__operators__.getitem_20[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_21[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.image.resize_21 (TFOpLa  (None, 128, 128, 64)         0         ['re_lu_71[0][0]',            \n",
      " mbda)                                                               'tf.__operators__.getitem_20[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_21[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)         (None, 128, 128, 32)         2080      ['tf.image.resize_20[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)         (None, 128, 128, 32)         2080      ['tf.image.resize_21[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 128, 128, 64)         0         ['conv2d_135[0][0]',          \n",
      " e)                                                                  'conv2d_136[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)         (None, 128, 128, 64)         4160      ['concatenate_10[0][0]']      \n",
      "                                                                                                  \n",
      " multiply_10 (Multiply)      (None, 128, 128, 64)         0         ['concatenate_10[0][0]',      \n",
      "                                                                     'conv2d_137[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)         (None, 128, 128, 64)         36928     ['multiply_10[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_90 (Ba  (None, 128, 128, 64)         256       ['conv2d_138[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_90 (ReLU)             (None, 128, 128, 64)         0         ['batch_normalization_90[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)         (None, 128, 128, 64)         36928     ['re_lu_90[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_91 (Ba  (None, 128, 128, 64)         256       ['conv2d_139[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_91 (ReLU)             (None, 128, 128, 64)         0         ['batch_normalization_91[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)         (None, 128, 128, 64)         36928     ['re_lu_91[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_92 (Ba  (None, 128, 128, 64)         256       ['conv2d_140[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_40 (Add)                (None, 128, 128, 64)         0         ['batch_normalization_92[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_90[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_92 (ReLU)             (None, 128, 128, 64)         0         ['add_40[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2  (None, 256, 256, 32)         8224      ['re_lu_92[0][0]']            \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_22 (TFO  (4,)                         0         ['conv2d_transpose_11[0][0]'] \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_23 (TFO  (4,)                         0         ['conv2d_transpose_11[0][0]'] \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape_22[0][0]'\n",
      " 2 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape_23[0][0]'\n",
      " 3 (SlicingOpLambda)                                                ]                             \n",
      "                                                                                                  \n",
      " tf.image.resize_22 (TFOpLa  (None, 256, 256, 32)         0         ['conv2d_transpose_11[0][0]', \n",
      " mbda)                                                               'tf.__operators__.getitem_22[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_23[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.image.resize_23 (TFOpLa  (None, 256, 256, 32)         0         ['re_lu_67[0][0]',            \n",
      " mbda)                                                               'tf.__operators__.getitem_22[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_23[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)         (None, 256, 256, 16)         528       ['tf.image.resize_22[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)         (None, 256, 256, 16)         528       ['tf.image.resize_23[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenat  (None, 256, 256, 32)         0         ['conv2d_141[0][0]',          \n",
      " e)                                                                  'conv2d_142[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)         (None, 256, 256, 32)         1056      ['concatenate_11[0][0]']      \n",
      "                                                                                                  \n",
      " multiply_11 (Multiply)      (None, 256, 256, 32)         0         ['concatenate_11[0][0]',      \n",
      "                                                                     'conv2d_143[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)         (None, 256, 256, 32)         9248      ['multiply_11[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_93 (Ba  (None, 256, 256, 32)         128       ['conv2d_144[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_93 (ReLU)             (None, 256, 256, 32)         0         ['batch_normalization_93[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)         (None, 256, 256, 32)         9248      ['re_lu_93[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_94 (Ba  (None, 256, 256, 32)         128       ['conv2d_145[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_94 (ReLU)             (None, 256, 256, 32)         0         ['batch_normalization_94[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)         (None, 256, 256, 32)         9248      ['re_lu_94[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_95 (Ba  (None, 256, 256, 32)         128       ['conv2d_146[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_41 (Add)                (None, 256, 256, 32)         0         ['batch_normalization_95[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_93[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_95 (ReLU)             (None, 256, 256, 32)         0         ['add_41[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSamplin  (None, 256, 256, 64)         0         ['re_lu_92[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSamplin  (None, 256, 256, 128)        0         ['re_lu_89[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " main_output (Conv2D)        (None, 256, 256, 1)          33        ['re_lu_95[0][0]']            \n",
      "                                                                                                  \n",
      " aux_output_1 (Conv2D)       (None, 256, 256, 1)          65        ['up_sampling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " aux_output_2 (Conv2D)       (None, 256, 256, 1)          129       ['up_sampling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14419267 (55.01 MB)\n",
      "Trainable params: 14408451 (54.96 MB)\n",
      "Non-trainable params: 10816 (42.25 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# =====================================\n",
    "# ðŸ“Š SAME CSV INPUT PIPELINE\n",
    "# =====================================\n",
    "\n",
    "# Load the CSVs without headers\n",
    "x_train_paths = pd.read_csv(r'image_paths.csv', header=None)[0]\n",
    "y_train_paths = pd.read_csv(r'mask_paths.csv', header=None)[0]\n",
    "\n",
    "# Preprocess data functions (SAME as before)\n",
    "def preprocess_image(img_path):\n",
    "    \"\"\"Preprocess input image: resize, normalize, and add channel dimension.\"\"\"\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (256, 256))  # Resize to model's input size\n",
    "    img = img / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "    return img\n",
    "\n",
    "def preprocess_mask(mask_path):\n",
    "    \"\"\"Preprocess mask: resize, normalize, and add channel dimension.\"\"\"\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (256, 256))\n",
    "    mask = mask / 255.0\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return mask\n",
    "\n",
    "# ðŸš€ ENHANCED GENERATOR FOR DEEP SUPERVISION (Multiple Outputs)\n",
    "def dag_image_mask_generator(image_paths, mask_paths, batch_size=8):\n",
    "    \"\"\"\n",
    "    Enhanced generator for DAG-VNet with deep supervision.\n",
    "    Returns same mask for all three outputs (main, aux1, aux2)\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for i in range(0, len(image_paths), batch_size):\n",
    "            batch_image_paths = image_paths[i:i+batch_size]\n",
    "            batch_mask_paths = mask_paths[i:i+batch_size]\n",
    "            \n",
    "            # Preprocess batch of images and masks\n",
    "            batch_images = np.array([preprocess_image(path) for path in batch_image_paths])\n",
    "            batch_masks = np.array([preprocess_mask(path) for path in batch_mask_paths])\n",
    "            \n",
    "            # For deep supervision: same mask for all three outputs\n",
    "            yield batch_images, {\n",
    "                \"main_output\": batch_masks,\n",
    "                \"aux_output_1\": batch_masks,  # Same mask, different scales\n",
    "                \"aux_output_2\": batch_masks\n",
    "            }\n",
    "\n",
    "# =====================================\n",
    "# ðŸ§  TRUE DAG-VNET MODEL ARCHITECTURE\n",
    "# =====================================\n",
    "\n",
    "def residual_block(x, filters, kernel_size=(3, 3)):\n",
    "    \"\"\"V-Net style residual block\"\"\"\n",
    "    shortcut = x\n",
    "    \n",
    "    # First conv\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # Second conv\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Adjust shortcut dimensions if needed\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = tf.keras.layers.Conv2D(filters, (1, 1), padding=\"same\")(shortcut)\n",
    "    \n",
    "    # Add residual connection\n",
    "    x = tf.keras.layers.Add()([x, shortcut])\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def dag_multi_scale_fusion(feature_maps, target_filters):\n",
    "    \"\"\"True DAG fusion with attention, dynamic resizing.\"\"\"\n",
    "    target_h = tf.shape(feature_maps[0])[1]\n",
    "    target_w = tf.shape(feature_maps[0])[2]\n",
    "\n",
    "    resized_features = []\n",
    "    for fm in feature_maps:\n",
    "        fm_resized = tf.image.resize(fm, (target_h, target_w), method=\"bilinear\")\n",
    "        fm_resized = tf.keras.layers.Conv2D(\n",
    "            target_filters // len(feature_maps), (1, 1), padding=\"same\"\n",
    "        )(fm_resized)\n",
    "        resized_features.append(fm_resized)\n",
    "\n",
    "    merged = tf.keras.layers.Concatenate()(resized_features)\n",
    "    attention = tf.keras.layers.Conv2D(target_filters, (1, 1), activation=\"sigmoid\")(merged)\n",
    "    fused = tf.keras.layers.Multiply()([merged, attention])\n",
    "    output = tf.keras.layers.Conv2D(target_filters, (3, 3), padding=\"same\")(fused)\n",
    "    output = tf.keras.layers.BatchNormalization()(output)\n",
    "    output = tf.keras.layers.ReLU()(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def true_dag_vnet(input_shape=(256, 256, 1), num_classes=1):\n",
    "    \"\"\"\n",
    "    True DAG-VNet with V-Net backbone and complex DAG connections\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder with residual blocks (V-Net style)\n",
    "    # Level 1\n",
    "    e1 = residual_block(inputs, 32)\n",
    "    e1 = residual_block(e1, 32)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(e1)\n",
    "    \n",
    "    # Level 2  \n",
    "    e2 = residual_block(p1, 64)\n",
    "    e2 = residual_block(e2, 64)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(e2)\n",
    "    \n",
    "    # Level 3\n",
    "    e3 = residual_block(p2, 128)\n",
    "    e3 = residual_block(e3, 128)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(e3)\n",
    "    \n",
    "    # Level 4\n",
    "    e4 = residual_block(p3, 256)\n",
    "    e4 = residual_block(e4, 256)\n",
    "    p4 = tf.keras.layers.MaxPooling2D((2, 2))(e4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    bottleneck = residual_block(p4, 512)\n",
    "    bottleneck = residual_block(bottleneck, 512)\n",
    "    \n",
    "    # Decoder with true DAG connections\n",
    "    # Level 4 decoder - connects to all encoder levels\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding=\"same\")(bottleneck)\n",
    "    d4 = dag_multi_scale_fusion([u4, e4], 256)  # Start with fewer connections to avoid complexity\n",
    "    d4 = residual_block(d4, 256)\n",
    "    \n",
    "    # Level 3 decoder - connects to multiple levels including previous decoder\n",
    "    u3 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(d4)\n",
    "    d3 = dag_multi_scale_fusion([u3, e3], 128)\n",
    "    d3 = residual_block(d3, 128)\n",
    "    \n",
    "    # Level 2 decoder\n",
    "    u2 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(d3)\n",
    "    d2 = dag_multi_scale_fusion([u2, e2], 64)\n",
    "    d2 = residual_block(d2, 64)\n",
    "    \n",
    "    # Level 1 decoder\n",
    "    u1 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding=\"same\")(d2)\n",
    "    d1 = dag_multi_scale_fusion([u1, e1], 32)\n",
    "    d1 = residual_block(d1, 32)\n",
    "    \n",
    "    # Output with deep supervision (another DAG concept)\n",
    "    # Multiple output heads for different scales\n",
    "    out_main = tf.keras.layers.Conv2D(num_classes, (1, 1), activation=\"sigmoid\", name=\"main_output\")(d1)\n",
    "    \n",
    "    # Deep supervision outputs (optional)\n",
    "    out_aux1 = tf.keras.layers.Conv2D(num_classes, (1, 1), activation=\"sigmoid\", name=\"aux_output_1\")(\n",
    "        tf.keras.layers.UpSampling2D((2, 2))(d2)\n",
    "    )\n",
    "    out_aux2 = tf.keras.layers.Conv2D(num_classes, (1, 1), activation=\"sigmoid\", name=\"aux_output_2\")(\n",
    "        tf.keras.layers.UpSampling2D((4, 4))(d3)\n",
    "    )\n",
    "    \n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=inputs, \n",
    "        outputs=[out_main, out_aux1, out_aux2],\n",
    "        name=\"True_DAG_VNet\"\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =====================================\n",
    "# ðŸš€ MODEL CREATION AND COMPILATION\n",
    "# =====================================\n",
    "\n",
    "# Create the generator for training data\n",
    "train_generator = dag_image_mask_generator(x_train_paths, y_train_paths, batch_size=8)\n",
    "\n",
    "# Create and compile true DAG-VNet\n",
    "model = true_dag_vnet(input_shape=(256, 256, 1), num_classes=1)\n",
    "\n",
    "# Custom loss for deep supervision\n",
    "def dag_combined_loss(y_true, y_pred):\n",
    "    \"\"\"Combined loss for main and auxiliary outputs\"\"\"\n",
    "    main_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred[0])\n",
    "    aux_loss1 = tf.keras.losses.binary_crossentropy(y_true, y_pred[1]) \n",
    "    aux_loss2 = tf.keras.losses.binary_crossentropy(y_true, y_pred[2])\n",
    "    \n",
    "    # Weighted combination\n",
    "    total_loss = main_loss + 0.5 * aux_loss1 + 0.25 * aux_loss2\n",
    "    return total_loss\n",
    "\n",
    "# Compile model with multiple outputs\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss={\n",
    "        \"main_output\": \"binary_crossentropy\",\n",
    "        \"aux_output_1\": \"binary_crossentropy\", \n",
    "        \"aux_output_2\": \"binary_crossentropy\"\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"main_output\": 1.0,\n",
    "        \"aux_output_1\": 0.5,\n",
    "        \"aux_output_2\": 0.25\n",
    "    },\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "print(\"ðŸ§  True DAG-VNet Model Summary:\")\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Starting Training...\n",
      "ðŸ“Š Total training samples: 29940\n",
      "ðŸ“¦ Batch size: 8\n",
      "ðŸ“ˆ Steps per epoch: 3742\n",
      "Epoch 1/25\n",
      "3742/3742 [==============================] - 510s 130ms/step - loss: 0.5314 - main_output_loss: 0.3026 - aux_output_1_loss: 0.3037 - aux_output_2_loss: 0.3078 - main_output_accuracy: 0.8630 - aux_output_1_accuracy: 0.8616 - aux_output_2_accuracy: 0.8605\n",
      "Epoch 2/25\n",
      "3742/3742 [==============================] - 489s 130ms/step - loss: 0.5029 - main_output_loss: 0.2869 - aux_output_1_loss: 0.2873 - aux_output_2_loss: 0.2894 - main_output_accuracy: 0.8702 - aux_output_1_accuracy: 0.8688 - aux_output_2_accuracy: 0.8677\n",
      "Epoch 3/25\n",
      "3742/3742 [==============================] - 487s 130ms/step - loss: 0.4958 - main_output_loss: 0.2827 - aux_output_1_loss: 0.2837 - aux_output_2_loss: 0.2849 - main_output_accuracy: 0.8714 - aux_output_1_accuracy: 0.8702 - aux_output_2_accuracy: 0.8695\n",
      "Epoch 4/25\n",
      "3742/3742 [==============================] - 487s 130ms/step - loss: 0.4924 - main_output_loss: 0.2808 - aux_output_1_loss: 0.2817 - aux_output_2_loss: 0.2829 - main_output_accuracy: 0.8721 - aux_output_1_accuracy: 0.8712 - aux_output_2_accuracy: 0.8704\n",
      "Epoch 5/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4893 - main_output_loss: 0.2792 - aux_output_1_loss: 0.2799 - aux_output_2_loss: 0.2806 - main_output_accuracy: 0.8727 - aux_output_1_accuracy: 0.8719 - aux_output_2_accuracy: 0.8712\n",
      "Epoch 6/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4876 - main_output_loss: 0.2783 - aux_output_1_loss: 0.2789 - aux_output_2_loss: 0.2795 - main_output_accuracy: 0.8731 - aux_output_1_accuracy: 0.8723 - aux_output_2_accuracy: 0.8717\n",
      "Epoch 7/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4857 - main_output_loss: 0.2773 - aux_output_1_loss: 0.2777 - aux_output_2_loss: 0.2781 - main_output_accuracy: 0.8733 - aux_output_1_accuracy: 0.8727 - aux_output_2_accuracy: 0.8723\n",
      "Epoch 8/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4845 - main_output_loss: 0.2767 - aux_output_1_loss: 0.2769 - aux_output_2_loss: 0.2775 - main_output_accuracy: 0.8735 - aux_output_1_accuracy: 0.8729 - aux_output_2_accuracy: 0.8726\n",
      "Epoch 9/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4828 - main_output_loss: 0.2756 - aux_output_1_loss: 0.2760 - aux_output_2_loss: 0.2768 - main_output_accuracy: 0.8737 - aux_output_1_accuracy: 0.8735 - aux_output_2_accuracy: 0.8729\n",
      "Epoch 10/25\n",
      "3742/3742 [==============================] - 485s 130ms/step - loss: 0.4820 - main_output_loss: 0.2751 - aux_output_1_loss: 0.2756 - aux_output_2_loss: 0.2763 - main_output_accuracy: 0.8738 - aux_output_1_accuracy: 0.8736 - aux_output_2_accuracy: 0.8731\n",
      "Epoch 11/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4809 - main_output_loss: 0.2745 - aux_output_1_loss: 0.2749 - aux_output_2_loss: 0.2757 - main_output_accuracy: 0.8739 - aux_output_1_accuracy: 0.8738 - aux_output_2_accuracy: 0.8734\n",
      "Epoch 12/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4802 - main_output_loss: 0.2741 - aux_output_1_loss: 0.2744 - aux_output_2_loss: 0.2753 - main_output_accuracy: 0.8741 - aux_output_1_accuracy: 0.8740 - aux_output_2_accuracy: 0.8737\n",
      "Epoch 13/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4795 - main_output_loss: 0.2738 - aux_output_1_loss: 0.2741 - aux_output_2_loss: 0.2748 - main_output_accuracy: 0.8743 - aux_output_1_accuracy: 0.8742 - aux_output_2_accuracy: 0.8739\n",
      "Epoch 14/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4791 - main_output_loss: 0.2735 - aux_output_1_loss: 0.2740 - aux_output_2_loss: 0.2744 - main_output_accuracy: 0.8744 - aux_output_1_accuracy: 0.8743 - aux_output_2_accuracy: 0.8741\n",
      "Epoch 15/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4791 - main_output_loss: 0.2735 - aux_output_1_loss: 0.2739 - aux_output_2_loss: 0.2747 - main_output_accuracy: 0.8743 - aux_output_1_accuracy: 0.8743 - aux_output_2_accuracy: 0.8740\n",
      "Epoch 16/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4783 - main_output_loss: 0.2731 - aux_output_1_loss: 0.2734 - aux_output_2_loss: 0.2742 - main_output_accuracy: 0.8745 - aux_output_1_accuracy: 0.8745 - aux_output_2_accuracy: 0.8742\n",
      "Epoch 17/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4784 - main_output_loss: 0.2731 - aux_output_1_loss: 0.2736 - aux_output_2_loss: 0.2742 - main_output_accuracy: 0.8744 - aux_output_1_accuracy: 0.8744 - aux_output_2_accuracy: 0.8741\n",
      "Epoch 18/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4780 - main_output_loss: 0.2729 - aux_output_1_loss: 0.2733 - aux_output_2_loss: 0.2740 - main_output_accuracy: 0.8746 - aux_output_1_accuracy: 0.8748 - aux_output_2_accuracy: 0.8744\n",
      "Epoch 19/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4770 - main_output_loss: 0.2723 - aux_output_1_loss: 0.2728 - aux_output_2_loss: 0.2734 - main_output_accuracy: 0.8746 - aux_output_1_accuracy: 0.8748 - aux_output_2_accuracy: 0.8745\n",
      "Epoch 20/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4797 - main_output_loss: 0.2738 - aux_output_1_loss: 0.2742 - aux_output_2_loss: 0.2751 - main_output_accuracy: 0.8741 - aux_output_1_accuracy: 0.8742 - aux_output_2_accuracy: 0.8737\n",
      "Epoch 21/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4784 - main_output_loss: 0.2732 - aux_output_1_loss: 0.2735 - aux_output_2_loss: 0.2742 - main_output_accuracy: 0.8743 - aux_output_1_accuracy: 0.8744 - aux_output_2_accuracy: 0.8741\n",
      "Epoch 22/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4769 - main_output_loss: 0.2722 - aux_output_1_loss: 0.2726 - aux_output_2_loss: 0.2733 - main_output_accuracy: 0.8747 - aux_output_1_accuracy: 0.8748 - aux_output_2_accuracy: 0.8745\n",
      "Epoch 23/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4761 - main_output_loss: 0.2718 - aux_output_1_loss: 0.2721 - aux_output_2_loss: 0.2729 - main_output_accuracy: 0.8750 - aux_output_1_accuracy: 0.8752 - aux_output_2_accuracy: 0.8747\n",
      "Epoch 24/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4752 - main_output_loss: 0.2713 - aux_output_1_loss: 0.2716 - aux_output_2_loss: 0.2724 - main_output_accuracy: 0.8751 - aux_output_1_accuracy: 0.8752 - aux_output_2_accuracy: 0.8749\n",
      "Epoch 25/25\n",
      "3742/3742 [==============================] - 486s 130ms/step - loss: 0.4743 - main_output_loss: 0.2708 - aux_output_1_loss: 0.2711 - aux_output_2_loss: 0.2718 - main_output_accuracy: 0.8752 - aux_output_1_accuracy: 0.8755 - aux_output_2_accuracy: 0.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: True_DAG_VNet_savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: True_DAG_VNet_savedmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: True_DAG_VNet_tf_format/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: True_DAG_VNet_tf_format/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Training completed successfully!\n",
      "ðŸ’¾ Model saved in formats: .keras, .h5, SavedModel folder, and tf_format\n",
      "TensorFlow version: 2.16.2\n",
      "Keras version: 3.11.3\n",
      "tf_keras version: 2.16.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================\n",
    "# ðŸ‹ï¸ TRAINING THE MODEL\n",
    "# =====================================\n",
    "\n",
    "print(\"\\nðŸš€ Starting Training...\")\n",
    "print(f\"ðŸ“Š Total training samples: {len(x_train_paths)}\")\n",
    "print(f\"ðŸ“¦ Batch size: 8\")\n",
    "print(f\"ðŸ“ˆ Steps per epoch: {len(x_train_paths) // 8}\")\n",
    "\n",
    "# Train the model using the batch generator\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(x_train_paths) // 8,\n",
    "    epochs=25,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# After training your model\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. Save in .keras format (new Keras native format)\n",
    "model.save(\"True_DAG_VNet_model.keras\")\n",
    "\n",
    "# 2. Save in HDF5 (.h5) format (older, widely supported)\n",
    "model.save(\"True_DAG_VNet_model.h5\")\n",
    "\n",
    "# 3. Save in TensorFlow SavedModel directory format (most portable)\n",
    "model.save(\"True_DAG_VNet_savedmodel\", save_format=\"tf\")\n",
    "\n",
    "# 4. Explicit TensorFlow SavedModel export (alternative API)\n",
    "tf.saved_model.save(model, \"True_DAG_VNet_tf_format\")\n",
    "\n",
    "print(\"\\nâœ… Training completed successfully!\")\n",
    "print(\"ðŸ’¾ Model saved in formats: .keras, .h5, SavedModel folder, and tf_format\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "try:\n",
    "    import keras\n",
    "    print(\"Keras version:\", keras.__version__)\n",
    "except ImportError:\n",
    "    print(\"Keras not installed\")\n",
    "\n",
    "try:\n",
    "    import tf_keras\n",
    "    print(\"tf_keras version:\", tf_keras.__version__)\n",
    "except ImportError:\n",
    "    print(\"tf_keras not installed, using tf.keras instead\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Ready for inference! Use the saved model for predictions.\n",
      "ðŸ’¡ The model outputs 3 predictions: main_output (use this), aux_output_1, aux_output_2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================\n",
    "# ðŸ” OPTIONAL: VALIDATION SPLIT\n",
    "# =====================================\n",
    "\n",
    "def create_train_val_generators(image_paths, mask_paths, validation_split=0.2, batch_size=8):\n",
    "    \"\"\"Create training and validation generators with data split.\"\"\"\n",
    "    total_samples = len(image_paths)\n",
    "    val_samples = int(total_samples * validation_split)\n",
    "    \n",
    "    # Shuffle indices\n",
    "    indices = np.random.permutation(total_samples)\n",
    "    \n",
    "    # Split indices\n",
    "    val_indices = indices[:val_samples]\n",
    "    train_indices = indices[val_samples:]\n",
    "    \n",
    "    # Create splits\n",
    "    x_train = image_paths.iloc[train_indices].reset_index(drop=True)\n",
    "    y_train = mask_paths.iloc[train_indices].reset_index(drop=True)\n",
    "    x_val = image_paths.iloc[val_indices].reset_index(drop=True)\n",
    "    y_val = mask_paths.iloc[val_indices].reset_index(drop=True)\n",
    "    \n",
    "    # Create generators\n",
    "    train_gen = dag_image_mask_generator(x_train, y_train, batch_size)\n",
    "    val_gen = dag_image_mask_generator(x_val, y_val, batch_size)\n",
    "    \n",
    "    return train_gen, val_gen, len(x_train), len(x_val)\n",
    "\n",
    "# Uncomment to use validation split:\n",
    "\"\"\"\n",
    "print(\"\\nðŸ”„ Creating train/validation split...\")\n",
    "train_gen, val_gen, train_samples, val_samples = create_train_val_generators(\n",
    "    x_train_paths, y_train_paths, validation_split=0.2, batch_size=8\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Training samples: {train_samples}\")\n",
    "print(f\"ðŸ” Validation samples: {val_samples}\")\n",
    "\n",
    "# Train with validation\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_samples // 8,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_samples // 8,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# =====================================\n",
    "# ðŸ“ˆ TRAINING VISUALIZATION (Optional)\n",
    "# =====================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['main_output_accuracy'], label='Main Output Accuracy')\n",
    "if 'val_main_output_accuracy' in history.history:\n",
    "    plt.plot(history.history['val_main_output_accuracy'], label='Val Main Output Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nðŸŽ¯ Ready for inference! Use the saved model for predictions.\")\n",
    "print(\"ðŸ’¡ The model outputs 3 predictions: main_output (use this), aux_output_1, aux_output_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXFugvkVt_DH",
    "outputId": "2f84c94f-665d-4d22-90ad-3dbe4412f122"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue_DAG_VNet_savedmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('True_DAG_VNet_savedmodel', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n",
      "3.11.3\n",
      "2.16.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "\n",
    "import tf_keras\n",
    "print(tf_keras.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nMnUqqE-uFPG"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Preprocess the input image: resize, normalize, and add a channel dimension.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    image = np.expand_dims(image, axis=-1)  # Add channel dimension\n",
    "    return image\n",
    "\n",
    "from skimage.measure import regionprops, label\n",
    "\n",
    "def predict_and_calculate_head_circumference(image_path, model, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Predict the segmentation mask for the given image and calculate head circumference.\n",
    "    \"\"\"\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image_path, target_size)\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Predict mask\n",
    "    pred_mask = model.predict(image)[0, :, :, 0]  # Remove batch dimension\n",
    "    pred_mask = (pred_mask > 0.5).astype(np.uint8)  # Binary thresholding\n",
    "\n",
    "    # Label connected regions in the binary mask\n",
    "    labeled_mask = label(pred_mask)\n",
    "    regions = regionprops(labeled_mask)\n",
    "\n",
    "    if regions:\n",
    "        # Get the perimeter of the largest region (assuming it's the head region)\n",
    "        largest_region = max(regions, key=lambda r: r.area)\n",
    "        circumference = largest_region.perimeter\n",
    "        return circumference\n",
    "    else:\n",
    "        print(\"No region detected!\")\n",
    "        return 0\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
